<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zhenghe-md.github.io","root":"/blog/","images":"/blog/images","scheme":"Mist","darkmode":false,"version":"8.27.0","exturl":false,"sidebar":{"position":"left","display":"remove","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"tomorrow-night"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null}},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/blog/js/config.js" defer></script>



<link rel="canonical" href="https://zhenghe-md.github.io/blog/2020/02/19/Cache-Policies/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://zhenghe-md.github.io/blog/2020/02/19/Cache-Policies/","path":"2020/02/19/Cache-Policies/","title":"缓存管理策略综述"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>缓存管理策略综述 | ZhengHe</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-172943223-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-172943223-1","only_pageview":false}</script>
  <script src="/blog/js/third-party/analytics/google-analytics.js" defer></script>








  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/blog/js/utils.js" defer></script><script src="/blog/js/next-boot.js" defer></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/blog/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/blog/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/blog/atom.xml" title="ZhengHe" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">ZhengHe</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-about"><a href="/blog/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
  </ul>
</nav>




</header>
    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zhenghe-md.github.io/blog/2020/02/19/Cache-Policies/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="ZhengHe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZhengHe">
      <meta itemprop="description" content="郑鹤的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="缓存管理策略综述 | ZhengHe">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          缓存管理策略综述
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-02-19 23:17:10" itemprop="dateCreated datePublished" datetime="2020-02-19T23:17:10+00:00">2020-02-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2026-02-03 00:59:11" itemprop="dateModified" datetime="2026-02-03T00:59:11+00:00">2026-02-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/" itemprop="url" rel="index"><span itemprop="name">系统设计</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/blog/2020/02/19/Cache-Policies/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/02/19/Cache-Policies/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>在计算机系统设计实践中，我们常常会遇到下图所示架构：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/coherence.jpg" width="400px"></p>
<p>为了解决单个存储器读吞吐无法满足要求的问题，常常需要在存储器上面增加一个或多个缓存。但由于相同的数据被复制到一个或多个地方，就容易引发数据一致性问题。<span id="more"></span>不一致的数据可能出现在<strong>同级
Cache 之间 (Cache Coherence) </strong>和<strong>上下级 Cache
之间</strong>。解决这些数据一致性问题的方案可以统称为 Cache
Policies。从本质上看，所有 Cache Policies
的设计目的都可以概括为：<strong>在增加一级缓存之后，系统看起来和没加缓存的行为一致，但得益于局部性原理，系统的读吞吐量提高、时延减少</strong>。</p>
<p>本文将探讨四个场景：</p>
<ol type="1">
<li>Cache Policy In Single-core Processor</li>
<li>Cache Coherence in Multi-core Processor</li>
<li>Cache Policy in Cache/DB Architecture</li>
<li>Cache Policy in Distributed DBMS Architecture</li>
</ol>
<h1 id="cache-policy-in-single-core-processor">Cache Policy in
Single-core Processor</h1>
<p>在单核 CPU 中，只有一套 Cache，因此只要确保写入 Cache
中的数据也写入到 Memory 即可。</p>
<p><img src="/blog/2020/02/19/Cache-Policies/single-core-cache-architecture.jpg" width="450px"></p>
<p>补充一些概念定义：数据在 Cache 与 Memory 之间移动的最小单位通常在 32
- 128 字节之间，Memory 中对应的最小单位数据称为 Cache Block，Cache
中与单个 Cache Block 对应的存储空间称为 Cache Line，在 Cache 中除了存储
Block 数据，还需要存储 Block 对应的唯一标识 <span class="math inline"><em>T</em></span> (Tag)，以及一个用于标记 Cache Line
是否有数据的有效位 <span class="math inline"><em>V</em></span>。完整对应关系如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/cache-block-and-cache-line.jpg" width="450px"></p>
<p>单核处理器下的 Cache Policy 要解决的问题可以被概括为：</p>
<blockquote>
<p>CPU 从 Cache 中读到的数据必须是最近写入的数据</p>
</blockquote>
<p>要满足定义，最简单的方式就是 Write-Through，即每次写入 Cache
时，也将数据写到 Memory 中。当之前写入的某数据 <span class="math inline"><em>D</em></span>
在某时刻被置换后，可以保证再次读入的数据是最近写入的数据。这里有个很明显的改进空间：只需要在数据
<span class="math inline"><em>D</em></span> 被置换前将其写入 Memory
即可。为此我们可以为每个 Cache Line 增加一个脏位 (Dirty Bit)，即：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/cache-line-with-dirty-bit.jpg" width="450px"></p>
<p>当其被写入时置为 1；当其被置换时，如果脏位为 1，则写出到
Memory，否则直接丢弃即可。以上所述的 Cache Policy 就是 Write-Back
Policy，也是目前在单核处理器中被广泛采用的 Cache Policy。</p>
<h1 id="cache-coherence-in-multi-core-processor">Cache Coherence in
Multi-core Processor</h1>
<p>‌在多核 CPU 中，如果这些核共用一套缓存，由于单套 Cache
的吞吐跟不上，无法达到最佳性能。</p>
<p><img src="/blog/2020/02/19/Cache-Policies/multicore-share-cache.jpg" width="600px"></p>
<p>这时候就需要在每个核上再加一级私有缓存：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/multicore-private-cache.jpg" width="400px"></p>
<p>假设在一个 4 核处理器中，内存地址 <span class="math inline"><em>M</em><em>A</em></span> 处最开始存储着整数
0，这时每个核都需要完成一个 read-modify-write 的操作，如下所示：</p>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Core 0</th>
<th>Core 1</th>
<th>Core 2</th>
<th>Core 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>LW Reg &lt;= A<br>Reg ++<br>SW Reg =&gt; A</td>
<td>LW Reg &lt;= A<br>Reg ++<br>SW Reg =&gt; A</td>
<td>LW Reg &lt;= A<br>Reg ++<br>SW Reg =&gt; A</td>
<td>LW Reg &lt;= A<br>Reg ++<br>SW Reg =&gt; A</td>
</tr>
</tbody>
</table>
<p>如果不加任何协议，当 4 个核都完成相应的操作后，内存地址 <span class="math inline"><em>M</em><em>A</em></span> 处可能存储着 1、2、3、4
中的任意值，这将影响并行计算的正确性。要保证并行计算的正确性，就必须保证每个核私有缓存之间的<strong>数据一致</strong>且永远是<strong>最新版本</strong>，可以想象，多核处理器上的各核之间必须遵守某种数据读写协议，才可能在获得多核计算力的同时维持计算的正确性，我们称这种数据读写协议为
Cache Coherence Protocols。</p>
<blockquote>
<p>Cache Coherence 的要求：</p>
<ol type="1">
<li>从内存地址 <span class="math inline"><em>M</em><em>X</em></span>
将数据 <span class="math inline"><em>D</em></span> 读入到核 <span class="math inline"><em>C</em>1</span> 的 Cache
中，在其它核没有写入数据到 MX 的情况下，读入的数据 <span class="math inline"><em>D</em></span> 必须是 <span class="math inline"><em>C</em>1</span> 最近写入的数据值。(单核 CPU 的
Cache Coherence 定义)</li>
<li>如果 <span class="math inline"><em>C</em>1</span> 写入数据到 <span class="math inline"><em>M</em><em>X</em></span>
中，经过足够长的一段时间后，在其它核没有写入数据的情况下，<span class="math inline"><em>C</em>2</span> 必须能够读入 <span class="math inline"><em>C</em>1</span> 写入的数据值。</li>
<li>针对地址 <span class="math inline"><em>M</em><em>X</em></span>
中的来自于各个核的写入操作必须被序列化，即在每个核眼中，数据的写入顺序相同。</li>
</ol>
</blockquote>
<h2 id="how-to-get-coherence">How To Get Coherence</h2>
<p>要在多核 CPU 中实现 Cache
Coherence，需要解决的根本问题是：<strong>让每个读操作在执行前能够获得所有最近的写操作历史</strong>。</p>
<p><strong>从写操作传递信息的内容出发</strong>，可以将 Cache Coherence
Protocols 划分为两类：<strong>Write-Update</strong> 和
<strong>Write-Invalidate</strong>。Write-Update
就是在写入数据时，将所有其它同级 Cache 中相同的 Cache Line
更新成最新数据；Write-Invalidate 就是在写入数据时，将所有其它同级 Cache
中相同的 Cache Line 标记为不合法。</p>
<p><strong>从写操作传递信息的方式出发</strong>，可以将 Cache Coherence
Protocols 划分为两类：<strong>Snooping</strong> 和
<strong>Directory</strong>。Snooping 将写数据的信息通过共享总线 (Shared
Bus) 广播给其它同级 Cache，同时保证写操作的顺序一致；Directory
在内存中为每个 Cache Line 标记额外的元信息，每个 Cache Line
的读写控制分而自治，将写数据的信息通过点对点的方式传递。</p>
<p>任何一种 Cache Coherence Protocol
基本都可以从这两个维度被归类为以下四类：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Write-Update</th>
<th>Write-Invalidate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Snooping</strong></td>
<td>Write-Update Snooping</td>
<td>Write-Invalidate Snooping</td>
</tr>
<tr class="even">
<td><strong>Directory</strong></td>
<td>Write-Update Directory</td>
<td>Write-Invalidate Directory</td>
</tr>
</tbody>
</table>
<h3 id="write-update-snooping-example">Write-Update Snooping
Example</h3>
<p>Cache 中的每条 Cache Line，除了记录数据本身，额外使用 1 bit 标记
<span class="math inline"><em>V</em></span> 是否有效，以及若干 bits
用于存储 Cache Block 的唯一标识 <span class="math inline"><em>T</em></span>。多个核内部的 Cache
通过一条共享总线与 Memory 相连，如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/write-update-snooping-coherence.jpg" width="650px"></p>
<ul>
<li>读取数据时，如果 Cache Line <span class="math inline"><em>T</em></span> 在 Cache 中的标记位 <span class="math inline"><em>V</em></span> 为 0，即触发 Cache Miss，Cache
会向 Memory 发起读请求；同时其它核的 Cache
会在总线上监听信息，但它们并不关心读请求，因此这个过程没有其它事情发生；如果目标
Block 在 Cache 中的标记位 <span class="math inline"><em>V</em></span> 为
1，则直接返回。</li>
<li>写入数据时，Cache 会将写请求通过总线发送到 Memory 中，并将 Memory
Block 中 <span class="math inline"><em>T</em></span> 对应 Cache Line
中的数据更新；同时，其它核的 Cache
会在总线上监听信息，如果发现内部也存有标识符为 <span class="math inline"><em>T</em></span> 的 Memory Block，则将其对应的
Cache Line 更新。</li>
<li>如果多个核同时发送针对 Cache Line <span class="math inline"><em>T</em></span>
的写请求，这时只有一个核可以获得总线的使用权，当整个 Write-Update
完整过程执行完毕后，其它核才能继续争夺总线的使用权。这也保证了 Cache
Coherence 定义中的第三条。</li>
</ul>
<h4 id="optimization-1-memory-writes">Optimization #1: Memory
Writes</h4>
<p>在原始的 Write-Update Snooping Example 中，我们采用 Write-Through
的方式，每当某个 Cache Line 写入数据时，都同时写穿到 Memory 中。本身
Memory
距离较远，读写数据时间长，就容易成为瓶颈，因此如果能够尽量使用类似
Write-Back 的策略，将数据保留在 Cache 中，用脏位 (dirty bit)
标记，等到其需要被替换时，再写入 Memory
中，就能优化该协议的整体性能。</p>
<p><img src="/blog/2020/02/19/Cache-Policies/write-update-snooping-coherence-op-1.jpg" width="650px"></p>
<ul>
<li>读取数据时，如果 Cache Line <span class="math inline"><em>T</em></span> 在 Cache 中的标记为 <span class="math inline"><em>V</em></span> 为 0，即触发 Cache Miss，Cache
会向 Memory 发起读请求；如果其它核的 Cache 已经拥有 <span class="math inline"><em>T</em></span>
对应的数据，则会<strong>截获该请求</strong>，直接将自己的数据传输给请求方，减少读穿。</li>
<li>写入数据时，Cache 会首先将自身 <span class="math inline"><em>T</em></span> 对应的数据更新，并且将脏位置为
1；然后将写数据的信息传入共享总线，这时其它核的 Cache
会同时监听到该消息。如果另一个核的 Cache 内部有相同的 Cache Line <span class="math inline"><em>T</em></span>，若它的脏位为 1，则会将 <span class="math inline"><em>T</em></span>
更新成为刚刚监听到的值，同时将脏位置为 0；若它的脏位为
0，则会直接修改数据。</li>
<li>如果 Cache 已满，被迫清出，则通过缓存置换算法选出 Cache Line <span class="math inline"><em>T</em>′</span>。若 <span class="math inline"><em>T</em>′</span> 的脏位为
1，则先将数据写出到缓存。</li>
</ul>
<p>总而言之：以上修改<strong>减少了读穿和写穿的频率</strong>，从而提高整体性能。</p>
<h4 id="optimization-2-bus-writes">Optimization #2: Bus Writes</h4>
<p>尽管增加 Opmization #1能减少读写 Memory
的资源消耗，但每次写数据时，依然要将信息发送到共享总线。大多数情况下，某
Cache Line <span class="math inline"><em>T</em></span>
对应的数据只有单个核会访问，因此如果能够提前识别其它核的 Cache
是否拥有该数据，避免向总线写入数据，就可以进一步提高整体性能。正因为此，我们可以尝试再加入一个共享标记位
(Shared Bit)，用于标记目标 Cache Line 是否同时存在于其它核的 Cache
中，如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/write-update-snooping-coherence-op-2.jpg" width="650px"></p>
<ul>
<li>读取数据时，如果发现其它 Cache 已经拥有 <span class="math inline"><em>T</em></span>
对应的数据，则二者都将共享标记位置为 1。</li>
<li>写入数据时，如果共享标记位为
1，则将写信息发送到共享总线；如果共享标记位为 0，则直接修改本地 Cache
Line 的值即可，并将脏位标记为 1，无需广播。</li>
</ul>
<h3 id="write-invalidate-snooping-example">Write-Invalidate Snooping
Example</h3>
<p>利用 Write-Update Snooping Example + Dirty Bit + Shared Bit
的结构，我们来看 Write-Invalidate Snooping 的工作模式。</p>
<ul>
<li>读取数据时，与 Write-Update Snooping 类似，<span class="math inline"><em>V</em></span> 为 0 时触发 Cache Miss；<span class="math inline"><em>V</em></span> 为 1 时直接读取本地缓存。</li>
<li>写入数据时，若 Cache Line <span class="math inline"><em>T</em></span> 的共享标记位 <span class="math inline"><em>S</em></span> 为
0，则只写入本地缓存；若共享标记位 <span class="math inline"><em>S</em></span> 为
1，则写入本地缓存的同时将写入信息发送到共享总线，其它拥有 <span class="math inline"><em>T</em></span> 的 Cache 将有效位 <span class="math inline"><em>V</em></span> 置为 0 即可。由于 Write-Invalidate
不需要更新其它 Cache 中的数据，因此发送到总线中的信息只需包含 Cache Line
的标识符 <span class="math inline"><em>T</em></span> 即可。</li>
</ul>
<p>与 Write-Update Snooping 不同，Write-Invalidatie Snooping
每次写入数据后，Cache 中 Cache Line <span class="math inline"><em>T</em></span> 的共享标记位 <span class="math inline"><em>S</em></span> 总是为 0，只有一个 Cache
中其对应的有效位 <span class="math inline"><em>V</em></span> 为
1，即全局只有一个 Cache 拥有有效数据。</p>
<h4 id="update-v.s.-invalidate-coherence">Update V.S. Invalidate
Coherence</h4>
<p>Update 与 Invalidate
究竟二者谁更优异？这需要实际运行模式的检验，考虑以下 3 种常见场景：</p>
<table>
<colgroup>
<col style="width: 26%">
<col style="width: 29%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>场景</th>
<th>Update</th>
<th>Invalidate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>瞬间针对同一个地址大量更新数据</td>
<td>❌ 每次写入都需要更新其它 Cache (<span class="math inline"><em>S</em> = 1</span>)</td>
<td>✅ 第一次写入之后就不需要再更新</td>
</tr>
<tr class="even">
<td>在同一个 Cache Line 上更新不同部分 (Words)</td>
<td>❌ 每个 WORD 写入都需要更新其它 Cache (<span class="math inline"><em>S</em> = 1</span>)</td>
<td>✅ 第一次写入之后就不需要再更新</td>
</tr>
<tr class="odd">
<td>生产者/消费者</td>
<td>✅ 生产者修改完数据后，直接更新消费者的数据</td>
<td>❌ 每次生产完数据都需要 Invalidate；每次消费都会发生 Cache
Miss，更多的总线吞吐</td>
</tr>
</tbody>
</table>
<p>尽管二者看起来各有千秋，<strong>在实践中普遍被采用的还是 Invalidate
Coherence</strong>。原因在于：在多核 CPU
的运行时中，一个最频繁的操作就是将一个 Thread
从一个核移动到另一个核上运行。分析一下这种场景：</p>
<table>
<colgroup>
<col style="width: 9%">
<col style="width: 45%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>场景</th>
<th>Update</th>
<th>Invalidate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>线程转移</td>
<td>❌ 线程在新的核上，总是需要更新旧核缓存</td>
<td>✅ 第一次写入之后，旧核中的缓存全部失效</td>
</tr>
</tbody>
</table>
<h4 id="msi-coherence">MSI Coherence</h4>
<p>在 Write-Invalide Snooping Example 中，我们在每个 Cache Line 上使用了
3 个标记位：有效位 <span class="math inline"><em>T</em></span>、脏位
<span class="math inline"><em>D</em></span> 和共享位 <span class="math inline"><em>S</em></span>，一共可以表示 8 个状态。每个 Cache
Line 真的需要 8 个状态吗？我们发现实际上每个 Cache Line 只需 3
个状态就足够实现 Write-Invalide Snooping Protocol：</p>
<ul>
<li>MODIFIED：修改且独占</li>
<li>SHARED：共享</li>
<li>INVALID：无效</li>
</ul>
<p>其状态机如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/msi.jpg" width="500px"></p>
<p>表示 3 个状态只需要 2 bits，这种更简单的 Write-Invalid Snooping
Protocol 被称为 MSI。尽管 MSI
能达到目的，但它在多个场景下仍存在效率问题，因此也有相应的改进版本
MOSI、MOESI 被提出，这里不再赘述。</p>
<h3 id="directory-protocols">Directory Protocols</h3>
<p>由于 Snooping 依赖基于共享总线的广播和监听，当 CPU 核数大于 8
个以后，共享总线就需要处理更多信号，解决更多冲突，成为瓶颈。因此<strong>抛弃广播网络、拥抱点对点网络通信是获得扩展性的前提</strong>。失去广播网络后，如何保证对同一个
Block 的写入顺序在各 CPU 核中保持一致，又重新成为难题。</p>
<p>Directory Protocols 正是为解决上述问题而被提出。要序列化对同一个
Block
的数据写入顺序，就必须将这些写入操作集中到一个节点上，但这并未要求对不同
Block 的写操作集中到一个节点上。于是我们可以<strong>将不同 Block
的控制权分散到不同分片中</strong>，这里的分片就是所谓的 Directory，每个
Directory 中包含若干个 Block 的控制信息。每个 Block 在 Directory
中记录的信息包含两个部分：</p>
<ul>
<li>Dirty Bit：是否被修改且未写回 Memory</li>
<li>Sharing Vector：哪些 Cache 拥有该 Block Data</li>
</ul>
<p>假设 CPU 中有 4 个核，每个核拥有私有 Cache，可以为每个 Block 记录 5
bits 信息：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/directory.jpg" width="500px"></p>
<p>这时整个架构如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/directory-based.jpg" width="500px"></p>
<p>这种分片的思想也是解决分布式系统横向扩展性的利器，值得深思。</p>
<h1 id="cache-policy-in-cachedb-architecture">Cache Policy in Cache/DB
Architecture</h1>
<p>‌在 Web APP 开发中，通过引入缓存中间件 (redis/memcache)
来减少数据库压力是十分常见的做法，这时服务架构通常如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/webapp-database-cache.jpg" width="600px"></p>
<p>如何从 Cache 和 DB 读取、写入数据就是 Cache/DB Architecture 下的
Cache Policy。与单核 CPU 中的 Cache Policy 不同，由于 Web APP
通常会部署在多个实例上，实践中几乎总是有多个进程在并行地增删改查数据。这时
Web APP 中不同进程写 Cache、写 DB 的顺序可以用 “一切皆有可能”
来概括。如果要保证二者之间数据的绝对一致，则必须要有分布式事务的支持，但无论是实现难度，还是分布式事务下的写性能下降，都不是开发者所期望的。因此在
Cache/DB Architecture 中，我们对 Cache Policy 的要求可以概括为：</p>
<blockquote>
<p>最终一致性：在写入 DB
之后，经过足够长的时间后总能访问到最近写入的数据</p>
</blockquote>
<h2 id="data-inconsistency">Data Inconsistency</h2>
<p>经过简单分析，我们可以找到很多出现数据不一致的场景。</p>
<ul>
<li>场景 1：假设写入数据时，先写 DB 后写 Cache：如果写 DB 成功，写 Cache
失败，那么 Cache 中就会继续保存着过时的数据。</li>
<li>场景 2：假设写入数据时，先写 DB 后写 Cache：如果有两个进程 A、B
同时执行写数据操作，有可能出现 A 写 DB、B 写 DB、B 写 Cache、A 写 Cache
的执行顺序，那么 Cache 中就会继续保存着过时的数据</li>
<li>…</li>
</ul>
<h2 id="cache-policies">Cache Policies</h2>
<h3 id="policy-1cache-expiry">Policy 1：Cache Expiry</h3>
<p>要实现 Cache/DB 中数据的最终一致，最简单的方式莫过于通过在 Cache
中为缓存数据设置过期时间，在经过这段时间后，会自动再次从数据库中重新加载数据，这样就能达到最终一致性。</p>
<p>这个方案的缺点也很明显，假如过期时间设置为 30 分钟，那么 Web APP
就需要容忍 30
分钟的数据不一致，这对很多服务来说几乎是无法接受的。当然，开发者可以把过期时间设短一些，但设得越短，读击穿到
DB 的频率也就越高，就和 Cache/DB Architecture 的初衷背道而驰。</p>
<h3 id="policy-2-cache-aside">Policy 2: Cache Aside</h3>
<p>Cache Aside 的读写逻辑如下：</p>
<table>
<colgroup>
<col style="width: 5%">
<col style="width: 94%">
</colgroup>
<thead>
<tr class="header">
<th>操作</th>
<th>逻辑</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>读取</td>
<td>Cache Hit: 直接返回缓存数据<br>Cache Miss：从 DB
中加载数据到缓存，并返回</td>
</tr>
<tr class="even">
<td>写入</td>
<td>写入 DB<br>将 Cache 中对应的数据删除</td>
</tr>
</tbody>
</table>
<p>这种方法适用于大多数场景，它通常也是实践中的标准做法。当然，这种做法也并非完美：</p>
<ul>
<li>假设有两个进程 A、B：A 写入 DB，B 读取数据，A 删除 Cache
中对应的数据，这时 B 读到了过时数据</li>
<li>假设有两个进程 A、B：B 从 DB 读取数据到内存，但未写入 Cache，A 写入
DB 并删除 Cache 中对应的数据，B 将内存中的数据写入
Cache，过时数据会一直存在于 Cache 中直到过期</li>
<li>A 写入 DB 后被杀死，过时数据会一直存在于 Cache 中直到过期</li>
<li>…</li>
</ul>
<p>上述做法也可以被称为 Write-Invalidate，即写入 DB 之后将 Cache
中对应的数据置为失效状态。<strong>为什么不使用类似 Write-Update
的做法</strong>？这样还能够节省一次 DB 与 Cache 之间的网络 I/O。写入 DB
后直接写入 Cache 的做法存在一个致命的场景：A、B
进程同时写入数据，其执行顺序如下：</p>
<ol type="1">
<li>A 写入 DB</li>
<li>B 写入 DB</li>
<li>B 写入 Cache</li>
<li>A 写入 Cache</li>
</ol>
<p>好家伙，这下好了…</p>
<h3 id="policy-3-read-through">Policy 3: Read Through</h3>
<p>Read Through 的读写逻辑如下：</p>
<table>
<colgroup>
<col style="width: 5%">
<col style="width: 94%">
</colgroup>
<thead>
<tr class="header">
<th>操作</th>
<th>逻辑</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>读取</td>
<td>服务只管从 Cache 中读取数据，如果出现 Cache Miss，由 Cache 负责从 DB
中加载数据</td>
</tr>
<tr class="even">
<td>写入</td>
<td>未指定</td>
</tr>
</tbody>
</table>
<p>这时候服务架构如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/webapp-database-cache-read-through.jpg" width="450px"></p>
<p>Read Through 的核心问题在于 Cache
需要支持逻辑嵌入，然而一般这种做法会导致运维、部署都不方便。</p>
<h3 id="policy-4-write-through">Policy 4: Write Through</h3>
<p>Write Through 与 Read Through 类似，就是在写入时由 Cache 层负责写入
DB 中。这种方案的问题主要包括：</p>
<ul>
<li>Cache 需要支持逻辑嵌入，导致运维、部署不方便</li>
<li>通常持久性 (Durability) 不在 Cache 的设计目标中，因此在写入 DB
之前，数据有可能发生丢失</li>
</ul>
<h3 id="poilicy-5-double-delete">Poilicy 5: Double Delete</h3>
<p>Double Delete 的读写逻辑如下：</p>
<table>
<colgroup>
<col style="width: 4%">
<col style="width: 95%">
</colgroup>
<thead>
<tr class="header">
<th>操作</th>
<th>逻辑</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>读取</td>
<td>Cache Hit：直接返回<br>Cache Miss：从 DB 中加载数据</td>
</tr>
<tr class="even">
<td>写入</td>
<td>将 Cache 中对应的数据删除<br>写入 DB<br>等一小段时间，如
500ms<br>再次将 Cache 中对应的数据删除</td>
</tr>
</tbody>
</table>
<p>其实它可以被理解成是 Cache Aside
的改进版，通过一段时间后的二次删除，避免因为并行问题导致 Cache
中的过时数据覆盖新写入数据的情况。</p>
<h3 id="policy-6write-behind">Policy 6：Write Behind</h3>
<p>Write Behind 的读写逻辑如下：</p>
<table>
<colgroup>
<col style="width: 4%">
<col style="width: 95%">
</colgroup>
<thead>
<tr class="header">
<th>操作</th>
<th>逻辑</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>读取</td>
<td>从 Cache 中读取数据</td>
</tr>
<tr class="even">
<td>写入</td>
<td>将数据写入 Cache<br>Cache 将写入操作记录投递到 MQ
中<br>异步进程消费 MQ 最终将数据写入 DB 中</td>
</tr>
</tbody>
</table>
<p>这时候服务的架构如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/webapp-database-cache-write-behind.jpg" width="600px"></p>
<p>这种做法可以极大地提高读写吞吐量，但缺点也比较明显：</p>
<ul>
<li>Cache 需要支持逻辑嵌入，导致运维、部署不方便</li>
<li>使用的 MQ 必须是 FIFO 队列，否则将导致数据写入 DB 的顺序错误</li>
</ul>
<p>Write Behind 还有一种变体，就是将写入的顺序调换：</p>
<table>
<colgroup>
<col style="width: 4%">
<col style="width: 95%">
</colgroup>
<thead>
<tr class="header">
<th>操作</th>
<th>逻辑</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>读取</td>
<td>从 Cache 中读取数据</td>
</tr>
<tr class="even">
<td>写入</td>
<td>将数据写入 DB<br>DB 将写入操作记录投递到 MQ 中<br>异步进程消费
MQ 最终将数据写入 Cache 中</td>
</tr>
</tbody>
</table>
<p>这时候服务的架构如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/webapp-database-cache-write-behind-variant.jpg" width="600px"></p>
<p>相较于原版 Write Behind，由于 DB 在复制的过程中已经实现了类似的
MQ，因此只需要开发解析复制日志的 DB 中间件，伪装成 Slave
节点，即可实现相应流程。整个架构中无需引入额外的
MQ，减少部署、运维成本。</p>
<h2 id="connections">Connections</h2>
<p>本节，我们从连接数的角度观察一下 Cache/DB Architecture 中不同 Cache
Policies 的架构。假设各上游服务与下游服务建立的连接池为固定大小 N。</p>
<p>考虑服务会被部署多个副本，在 Cache Expiry、Cache Aside 以及 Double
Delete 中，架构中各节点间的连接状态如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/webapp-database-cache-connections-1.jpg" width="600px"></p>
<p>每个服务实例都需要与 DB、Cache 建立 N
个连接，由于其它服务也需要访问相同的 DB、Cache
集群，这时候就会出现极高的连接数。</p>
<p>在 Read-Through、Wright-Through 以及 Write-Behind
中，架构中各节点的连接状态如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/webapp-database-cache-connections-2.jpg" width="600px"></p>
<p>每个服务实例都需要与 Cache 建立 N 个链接，Cache 与 MQ、MQ 与 DB
之间都只需要建立 N 个链接。</p>
<p>在 Write-Behind 的变体中，解析复制日志的中间件只需要与数据库建立 1
个连接即可，如下图所示：</p>
<p><img src="/blog/2020/02/19/Cache-Policies/webapp-database-cache-connections-3.jpg" width="600px"></p>
<h1 id="cache-policy-in-distributed-dbms-architecture">Cache Policy in
Distributed DBMS Architecture</h1>
<p>(TODO)</p>
<h2 id="summary">Summary</h2>
<p>本小节列举了多种 Cache
Policies，通常最常用的并不是设计最复杂的，具体场景需要具体分析，也许最简单的做法就能满足需求。Less
code, less bugs : )。</p>
<p><strong>转载请注明出处！</strong></p>
<h1 id="references">References‌</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://classroom.udacity.com/courses/ud007">Georgia Tech -
HPCA: Lesson 15 &amp; 24</a></li>
<li><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/engineering/cache-coherence">SienceDirect:
Cache Coherence</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Directory-based_cache_coherence">Wikipedia:
Directory-based cache coherence</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Directory-based_coherence#Directory_Node">Wikipedia:
Directory-based coherence</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Consistency_model">Wikipedia:
Consistency Model</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@TechExpertise/cache-coherence-problem-and-approaches-a18cdd48ee0e">Medium:
Cache Coherence Problem and Approaches</a></li>
<li><a target="_blank" rel="noopener" href="http://www.cs.utah.edu/~rajeev/cs7820/pres/7968-07.pdf">cs.utah.edu:
Directory-Based Cache Coherence</a></li>
<li><a target="_blank" rel="noopener" href="http://wiki.expertiza.ncsu.edu/index.php/CSC/ECE_506_Spring_2012/8a_cj">CSC/ECE
506 Sprint 2012/8a cj</a></li>
<li><a target="_blank" rel="noopener" href="https://akkadia.org/drepper/cpumemory.pdf">What Every
Programmer Should Know About Memory</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/12_directorycoherence.pdf">CMU:
Directory-Based Coherence I</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/13_directorycoherence2.pdf">CMU:
Directory-Based Coherence II</a></li>
<li><a target="_blank" rel="noopener" href="http://www.inf.ed.ac.uk/teaching/courses/pa/Notes/lecture06-directory.pdf">CS4
/MSc Parallel Architectures</a></li>
<li><a target="_blank" rel="noopener" href="https://yunpengn.github.io/blog/2019/05/04/consistent-redis-sql/">Consistency
between Redis Cache and SQL Database</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.oracle.com/cd/E13924_01/coh.340/e13819/readthrough.htm">Read-Through,
Write-Through, Write-Behind Caching and Refresh-Ahead</a></li>
<li><a target="_blank" rel="noopener" href="https://www.nginx.com/blog/nginx-high-performance-caching/">High-Performance
Caching with NGINX and NGINX Plus</a></li>
<li><a target="_blank" rel="noopener" href="http://simongui.github.io/2016/12/02/improving-cache-consistency.html">Improving
cache consistentcy</a></li>
<li><a target="_blank" rel="noopener" href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf">Scaling
Memcache at Facebook</a></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <a target="_blank" class="social-link" href="/blog/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
      </div>
  </div>
</div>


        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/blog/2020/02/18/Consistent-Hashing-and-Random-Trees-1997/" rel="prev" title="Consistent Hashing and Random Trees (1997)">
                  <i class="fa fa-angle-left"></i> Consistent Hashing and Random Trees (1997)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/blog/2020/02/26/Log-Structured-Merge-LSM-Tree-Usages-in-KV-Stores/" rel="next" title="用 LSM Tree 实现一个键值数据库 —— GopherConf 2017 演讲笔记">
                  用 LSM Tree 实现一个键值数据库 —— GopherConf 2017 演讲笔记 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">ZhengHe</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/ZhengHe-MD" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"zhenghe-hexo-blog","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/blog/js/third-party/comments/disqus.js" defer></script>

</body>
</html>
